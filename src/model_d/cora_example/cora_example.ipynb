{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Revised for our dataset from:\n",
    "# https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import neural_structured_learning as nsl\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Resets notebook state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### Experiment dataset\n",
    "TRAIN_DATA_PATH = 'G:/SEIS764/project/data/cora/cora/train_merged_examples.tfr'\n",
    "TEST_DATA_PATH = 'G:/SEIS764/project/data/cora/cora/test_examples.tfr'\n",
    "\n",
    "### Constants used to identify neighbor features in the input.\n",
    "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "NBR_WEIGHT_SUFFIX = '_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "  \"\"\"Hyperparameters used for training.\"\"\"\n",
    "  def __init__(self):\n",
    "    ### dataset parameters\n",
    "    self.num_classes = 7\n",
    "    self.max_seq_length = 1433\n",
    "    ### neural graph learning parameters\n",
    "    self.distance_type = nsl.configs.DistanceType.L2\n",
    "    self.graph_regularization_multiplier = 0.1\n",
    "    self.num_neighbors = 1\n",
    "    ### model architecture\n",
    "    self.num_fc_units = [50, 50]\n",
    "    ### training parameters\n",
    "    self.train_epochs = 100\n",
    "    self.batch_size = 128\n",
    "    self.dropout_rate = 0.5\n",
    "    ### eval parameters\n",
    "    self.eval_steps = None  # All instances in the test set are evaluated.\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_example(example_proto):\n",
    "  \"\"\"Extracts relevant fields from the `example_proto`.\n",
    "\n",
    "  Args:\n",
    "    example_proto: An instance of `tf.train.Example`.\n",
    "\n",
    "  Returns:\n",
    "    A pair whose first value is a dictionary containing relevant features\n",
    "    and whose second value contains the ground truth labels.\n",
    "  \"\"\"\n",
    "  # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
    "  # original raw text. A default value is required for examples that don't\n",
    "  # have the feature.\n",
    "  feature_spec = {\n",
    "      'words':\n",
    "          tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
    "                                tf.int64,\n",
    "                                default_value=tf.constant(\n",
    "                                    0,\n",
    "                                    dtype=tf.int64,\n",
    "                                    shape=[HPARAMS.max_seq_length])),\n",
    "      'label':\n",
    "          tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
    "  }\n",
    "  # We also extract corresponding neighbor features in a similar manner to\n",
    "  # the features above.\n",
    "  for i in range(HPARAMS.num_neighbors):\n",
    "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
    "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
    "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
    "        [HPARAMS.max_seq_length],\n",
    "        tf.int64,\n",
    "        default_value=tf.constant(\n",
    "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
    "\n",
    "    # We assign a default value of 0.0 for the neighbor weight so that\n",
    "    # graph regularization is done on samples based on their exact number\n",
    "    # of neighbors. In other words, non-existent neighbors are discounted.\n",
    "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
    "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
    "\n",
    "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "  labels = features.pop('label')\n",
    "  return features, labels\n",
    "\n",
    "\n",
    "def make_dataset(file_path, training=False):\n",
    "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
    "\n",
    "  Args:\n",
    "    file_path: Name of the file in the `.tfrecord` format containing\n",
    "      `tf.train.Example` objects.\n",
    "    training: Boolean indicating if we are in training mode.\n",
    "\n",
    "  Returns:\n",
    "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
    "    objects.\n",
    "  \"\"\"\n",
    "  dataset = tf.data.TFRecordDataset([file_path])\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(10000)\n",
    "  dataset = dataset.map(parse_example)\n",
    "  dataset = dataset.batch(HPARAMS.batch_size)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
    "test_dataset = make_dataset(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[0 3 6 2 3 2 1 3 6 3 2 3 6 6 0 1 6 5 1 3 2 1 2 3 4 2 2 0 2 2 1 1 2 6 0 6 6\n",
      " 3 3 0 6 2 0 6 5 2 3 2 1 6 3 4 3 2 6 2 2 1 2 1 4 0 2 2 2 3 4 4 2 2 2 2 3 0\n",
      " 1 6 3 6 1 3 3 3 2 2 6 3 2 1 3 3 3 2 0 4 5 0 2 2 2 0 5 1 6 3 2 1 6 6 5 3 1\n",
      " 1 6 5 2 1 3 0 1 1 1 0 6 5 2 0 6 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[5 2 2 2 1 2 6 3 2 3 6 1 3 6 4 4 2 3 3 0 2 0 5 2 1 0 6 3 6 4 2 2 3 0 4 2 2\n",
      " 2 2 3 2 2 2 0 2 2 2 2 4 2 3 4 0 2 6 2 1 4 2 0 0 1 4 2 6 0 5 2 2 3 2 5 2 5\n",
      " 2 3 2 2 2 2 2 6 6 3 2 4 2 6 3 2 2 6 2 4 2 2 1 3 4 6 0 0 2 4 2 1 3 6 6 2 6\n",
      " 6 6 1 4 6 4 3 6 6 0 0 2 6 2 4 0 0], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in test_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# In order to demonstrate the use of graph regularization, we build a base model for this problem first. We will use a simple feed-forward neural network with 2 hidden layers and dropout in between. We illustrate the creation of the base model using all model types supported by the tf.Keras framework -- sequential, functional, and subclass.\n",
    "\n",
    "# Sequential base model\n",
    "def make_mlp_sequential_model(hparams):\n",
    "  \"\"\"Creates a sequential multi-layer perceptron model.\"\"\"\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(\n",
    "      tf.keras.layers.InputLayer(\n",
    "          input_shape=(hparams.max_seq_length,), name='words'))\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  model.add(\n",
    "      tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32)))\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "    # For sequential models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    model.add(tf.keras.layers.Dropout(hparams.dropout_rate))\n",
    "  model.add(tf.keras.layers.Dense(hparams.num_classes, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp_functional_model(hparams):\n",
    "  \"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "  inputs = tf.keras.Input(\n",
    "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
    "\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  cur_layer = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.keras.backend.cast(x, tf.float32))(\n",
    "          inputs)\n",
    "\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "    # For functional models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(\n",
    "      hparams.num_classes, activation='softmax')(\n",
    "          cur_layer)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp_subclass_model(hparams):\n",
    "  \"\"\"Creates a multi-layer perceptron subclass model in Keras.\"\"\"\n",
    "\n",
    "  class MLP(tf.keras.Model):\n",
    "    \"\"\"Subclass model defining a multi-layer perceptron.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "      super(MLP, self).__init__()\n",
    "      # Input is already one-hot encoded in the integer format. We create a\n",
    "      # layer to cast it to floating point format here.\n",
    "      self.cast_to_float_layer = tf.keras.layers.Lambda(\n",
    "          lambda x: tf.keras.backend.cast(x, tf.float32))\n",
    "      self.dense_layers = [\n",
    "          tf.keras.layers.Dense(num_units, activation='relu')\n",
    "          for num_units in hparams.num_fc_units\n",
    "      ]\n",
    "      self.dropout_layer = tf.keras.layers.Dropout(hparams.dropout_rate)\n",
    "      self.output_layer = tf.keras.layers.Dense(\n",
    "          hparams.num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      cur_layer = self.cast_to_float_layer(inputs['words'])\n",
    "      for dense_layer in self.dense_layers:\n",
    "        cur_layer = dense_layer(cur_layer)\n",
    "        cur_layer = self.dropout_layer(cur_layer, training=training)\n",
    "\n",
    "      outputs = self.output_layer(cur_layer)\n",
    "\n",
    "      return outputs\n",
    "\n",
    "  return MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "words (InputLayer)           [(None, 1433)]            0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1433)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                71700     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a base MLP model using the functional API.\n",
    "# Alternatively, you can also create a sequential or subclass base model using\n",
    "# the make_mlp_sequential_model() or make_mlp_subclass_model() functions\n",
    "# respectively, defined above. Note that if a subclass model is used, its\n",
    "# summary cannot be generated until it is built.\n",
    "base_model_tag, base_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.9353 - accuracy: 0.1819\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.8490 - accuracy: 0.2956\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.7511 - accuracy: 0.3374\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.6544 - accuracy: 0.3717\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.5242 - accuracy: 0.4501\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.3938 - accuracy: 0.5271\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.2274 - accuracy: 0.5898\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.0652 - accuracy: 0.6371\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.9711 - accuracy: 0.6835\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.8629 - accuracy: 0.7132\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.7730 - accuracy: 0.7406\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.7108 - accuracy: 0.7777\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.6479 - accuracy: 0.8121\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6189 - accuracy: 0.8065\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5488 - accuracy: 0.8367\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5206 - accuracy: 0.8385\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4594 - accuracy: 0.8552\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4334 - accuracy: 0.8715\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4023 - accuracy: 0.8742\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3853 - accuracy: 0.8868\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3524 - accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3179 - accuracy: 0.9053\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3009 - accuracy: 0.9155\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2984 - accuracy: 0.9095\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.2853 - accuracy: 0.9188\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2780 - accuracy: 0.9193\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.2340 - accuracy: 0.9276\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2335 - accuracy: 0.9304\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2307 - accuracy: 0.9313\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2133 - accuracy: 0.9378\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2057 - accuracy: 0.9448\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2205 - accuracy: 0.9374\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1901 - accuracy: 0.9527\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1859 - accuracy: 0.9471\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1705 - accuracy: 0.9527\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1546 - accuracy: 0.9550\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1650 - accuracy: 0.9587\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1422 - accuracy: 0.9643\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1435 - accuracy: 0.9582\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1461 - accuracy: 0.9573\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1384 - accuracy: 0.9587\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1111 - accuracy: 0.9703\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1213 - accuracy: 0.9698\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1220 - accuracy: 0.9666\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1185 - accuracy: 0.9703\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1204 - accuracy: 0.9633\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1071 - accuracy: 0.9708\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1067 - accuracy: 0.9726\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1027 - accuracy: 0.9698\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1183 - accuracy: 0.9601\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9740\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1033 - accuracy: 0.9712\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1050 - accuracy: 0.9694\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 0.9745\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0955 - accuracy: 0.9768\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0832 - accuracy: 0.9773\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0840 - accuracy: 0.9777\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9745\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0826 - accuracy: 0.9759\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0794 - accuracy: 0.9759 0s - loss: 0.0831 - accuracy: \n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0798 - accuracy: 0.9782\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0814 - accuracy: 0.9777\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0798 - accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0804 - accuracy: 0.9796\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0831 - accuracy: 0.9787\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0737 - accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0736 - accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0741 - accuracy: 0.9768\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0635 - accuracy: 0.9805\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0765 - accuracy: 0.9754\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0712 - accuracy: 0.9782\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0702 - accuracy: 0.9810\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0717 - accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0675 - accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9847\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0641 - accuracy: 0.9814\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0567 - accuracy: 0.9865\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0716 - accuracy: 0.9805\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0691 - accuracy: 0.9796\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9856\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0617 - accuracy: 0.9833\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9898\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.9861\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9875\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.9884\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9861\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0586 - accuracy: 0.9838\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0457 - accuracy: 0.9861\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0585 - accuracy: 0.9861\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0479 - accuracy: 0.9879\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0488 - accuracy: 0.9884\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0446 - accuracy: 0.9879\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0529 - accuracy: 0.9870\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 0.9903\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0402 - accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0451 - accuracy: 0.9879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b72c54a748>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the base MLP model\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.3007 - accuracy: 0.7794\n",
      "\n",
      "\n",
      "Eval accuracy for  Base MLP model :  0.77938515\n",
      "Eval loss for  Base MLP model :  1.3007472813129426\n"
     ]
    }
   ],
   "source": [
    "# Helper function to print evaluation metrics.\n",
    "def print_metrics(model_desc, eval_metrics):\n",
    "  \"\"\"Prints evaluation metrics.\n",
    "\n",
    "  Args:\n",
    "    model_desc: A description of the model.\n",
    "    eval_metrics: A dictionary mapping metric names to corresponding values. It\n",
    "      must contain the loss and accuracy metrics.\n",
    "  \"\"\"\n",
    "  print('\\n')\n",
    "  print('Eval accuracy for ', model_desc, ': ', eval_metrics['accuracy'])\n",
    "  print('Eval loss for ', model_desc, ': ', eval_metrics['loss'])\n",
    "  if 'graph_loss' in eval_metrics:\n",
    "    print('Eval graph loss for ', model_desc, ': ', eval_metrics['graph_loss'])\n",
    "\n",
    "eval_results = dict(\n",
    "    zip(base_model.metrics_names,\n",
    "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('Base MLP model', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\seis764\\project\\venv_36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "g:\\seis764\\project\\venv_36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 143ms/step - loss: 1.9207 - accuracy: 0.2042 - graph_loss: 0.0101\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.8179 - accuracy: 0.3248 - graph_loss: 0.0150\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.7348 - accuracy: 0.3439 - graph_loss: 0.0306\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.6487 - accuracy: 0.3684 - graph_loss: 0.0497\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.5101 - accuracy: 0.4357 - graph_loss: 0.0717\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 1.3940 - accuracy: 0.5002 - graph_loss: 0.1068\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.2724 - accuracy: 0.5550 - graph_loss: 0.1380\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.1430 - accuracy: 0.6241 - graph_loss: 0.1668\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.0466 - accuracy: 0.6552 - graph_loss: 0.2070\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.9612 - accuracy: 0.6914 - graph_loss: 0.2137\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.8519 - accuracy: 0.7420 - graph_loss: 0.2451\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.7753 - accuracy: 0.7675 - graph_loss: 0.2519\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.7279 - accuracy: 0.7763 - graph_loss: 0.2674\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.6617 - accuracy: 0.8097 - graph_loss: 0.2737\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6214 - accuracy: 0.8255 - graph_loss: 0.2930\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.5653 - accuracy: 0.8311 - graph_loss: 0.2993\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.5446 - accuracy: 0.8436 - graph_loss: 0.2998\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4972 - accuracy: 0.8599 - graph_loss: 0.3050\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4592 - accuracy: 0.8715 - graph_loss: 0.3059\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.4167 - accuracy: 0.8872 - graph_loss: 0.3117\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3883 - accuracy: 0.8951 - graph_loss: 0.3278: 0s - loss: 0.4251 - accuracy: 0.8750 - graph_loss: 0.3\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3784 - accuracy: 0.8984 - graph_loss: 0.3323\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3615 - accuracy: 0.9118 - graph_loss: 0.3129\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3321 - accuracy: 0.9183 - graph_loss: 0.3320\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3287 - accuracy: 0.9132 - graph_loss: 0.3414\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3230 - accuracy: 0.9193 - graph_loss: 0.3253\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2902 - accuracy: 0.9225 - graph_loss: 0.3304\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.2867 - accuracy: 0.9309 - graph_loss: 0.3495\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2776 - accuracy: 0.9299 - graph_loss: 0.3482\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2379 - accuracy: 0.9452 - graph_loss: 0.3412\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2445 - accuracy: 0.9448 - graph_loss: 0.3454\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2403 - accuracy: 0.9401 - graph_loss: 0.3424\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.2332 - accuracy: 0.9411 - graph_loss: 0.3467\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2284 - accuracy: 0.9439 - graph_loss: 0.3392\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2213 - accuracy: 0.9401 - graph_loss: 0.3447\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2144 - accuracy: 0.9471 - graph_loss: 0.3371\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1898 - accuracy: 0.9568 - graph_loss: 0.3390\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1819 - accuracy: 0.9564 - graph_loss: 0.3421\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1875 - accuracy: 0.9573 - graph_loss: 0.3352\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1636 - accuracy: 0.9647 - graph_loss: 0.3470\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1834 - accuracy: 0.9615 - graph_loss: 0.3430\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1681 - accuracy: 0.9657 - graph_loss: 0.3374\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1536 - accuracy: 0.9689 - graph_loss: 0.3398\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1563 - accuracy: 0.9712 - graph_loss: 0.3422\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1540 - accuracy: 0.9684 - graph_loss: 0.3538\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1571 - accuracy: 0.9712 - graph_loss: 0.3474\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1520 - accuracy: 0.9708 - graph_loss: 0.3549\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1454 - accuracy: 0.9703 - graph_loss: 0.3399\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1377 - accuracy: 0.9740 - graph_loss: 0.3399\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1471 - accuracy: 0.9675 - graph_loss: 0.3492\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1395 - accuracy: 0.9689 - graph_loss: 0.3381\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1267 - accuracy: 0.9796 - graph_loss: 0.3363\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1273 - accuracy: 0.9800 - graph_loss: 0.3520\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1410 - accuracy: 0.9684 - graph_loss: 0.3492\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1304 - accuracy: 0.9745 - graph_loss: 0.3483\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1382 - accuracy: 0.9717 - graph_loss: 0.3463\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1215 - accuracy: 0.9759 - graph_loss: 0.3351\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1259 - accuracy: 0.9759 - graph_loss: 0.3441\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1144 - accuracy: 0.9763 - graph_loss: 0.3453\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1247 - accuracy: 0.9754 - graph_loss: 0.3481\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1154 - accuracy: 0.9777 - graph_loss: 0.3455\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1213 - accuracy: 0.9773 - graph_loss: 0.3454\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1205 - accuracy: 0.9754 - graph_loss: 0.3495\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1159 - accuracy: 0.9759 - graph_loss: 0.3501\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1123 - accuracy: 0.9805 - graph_loss: 0.3430\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1175 - accuracy: 0.9828 - graph_loss: 0.3554: 0s - loss: 0.1218 - accuracy: 0.9844 - graph_loss: 0.3\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0945 - accuracy: 0.9884 - graph_loss: 0.3356\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 0.9814 - graph_loss: 0.3464\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1105 - accuracy: 0.9768 - graph_loss: 0.3402\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1056 - accuracy: 0.9833 - graph_loss: 0.3470\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1082 - accuracy: 0.9800 - graph_loss: 0.3377\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0965 - accuracy: 0.9847 - graph_loss: 0.3463\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0993 - accuracy: 0.9838 - graph_loss: 0.3369\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1003 - accuracy: 0.9847 - graph_loss: 0.3393\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9820 - graph_loss: 0.350 - 0s 17ms/step - loss: 0.1040 - accuracy: 0.9810 - graph_loss: 0.3551\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0890 - accuracy: 0.9856 - graph_loss: 0.3434\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1031 - accuracy: 0.9796 - graph_loss: 0.3490\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0945 - accuracy: 0.9824 - graph_loss: 0.3457\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9814 - graph_loss: 0.3455\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1090 - accuracy: 0.9768 - graph_loss: 0.3513\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0902 - accuracy: 0.9861 - graph_loss: 0.3386\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0970 - accuracy: 0.9824 - graph_loss: 0.3372\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0997 - accuracy: 0.9828 - graph_loss: 0.3418\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0910 - accuracy: 0.9824 - graph_loss: 0.3436\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0896 - accuracy: 0.9828 - graph_loss: 0.3452\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0828 - accuracy: 0.9861 - graph_loss: 0.3328\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0907 - accuracy: 0.9833 - graph_loss: 0.3473\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0825 - accuracy: 0.9865 - graph_loss: 0.3304\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0869 - accuracy: 0.9861 - graph_loss: 0.3448\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0781 - accuracy: 0.9889 - graph_loss: 0.3405\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0908 - accuracy: 0.9828 - graph_loss: 0.3529\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0774 - accuracy: 0.9898 - graph_loss: 0.3449\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0888 - accuracy: 0.9824 - graph_loss: 0.3441\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9875 - graph_loss: 0.3401\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0798 - accuracy: 0.9875 - graph_loss: 0.3417\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0903 - accuracy: 0.9865 - graph_loss: 0.3355\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0778 - accuracy: 0.9879 - graph_loss: 0.3382\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0890 - accuracy: 0.9861 - graph_loss: 0.3490\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.9814 - graph_loss: 0.3382\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0768 - accuracy: 0.9916 - graph_loss: 0.3345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b72cce01d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a new base MLP model.\n",
    "base_reg_model_tag, base_reg_model = 'FUNCTIONAL', make_mlp_functional_model(\n",
    "    HPARAMS)\n",
    "\n",
    "# Wrap the base MLP model with graph regularization.\n",
    "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=HPARAMS.num_neighbors,\n",
    "    multiplier=HPARAMS.graph_regularization_multiplier,\n",
    "    distance_type=HPARAMS.distance_type,\n",
    "    sum_over_axis=-1)\n",
    "graph_reg_model = nsl.keras.GraphRegularization(base_reg_model,\n",
    "                                                graph_reg_config)\n",
    "graph_reg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "graph_reg_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 73ms/step - loss: 1.1488 - accuracy: 0.7957 - graph_loss: 0.0000e+00\n",
      "\n",
      "\n",
      "Eval accuracy for  MLP + graph regularization :  0.79566\n",
      "Eval loss for  MLP + graph regularization :  1.1488070607185363\n",
      "Eval graph loss for  MLP + graph regularization :  0.0\n"
     ]
    }
   ],
   "source": [
    "eval_results = dict(\n",
    "    zip(graph_reg_model.metrics_names,\n",
    "        graph_reg_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('MLP + graph regularization', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
