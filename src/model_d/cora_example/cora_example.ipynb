{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Revised for our dataset from:\n",
    "# https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import neural_structured_learning as nsl\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# Resets notebook state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### Experiment dataset\n",
    "TRAIN_DATA_PATH = '../../../data/cora/cora/train_merged_examples.tfr'\n",
    "TEST_DATA_PATH = '../../../data/cora/cora/test_examples.tfr'\n",
    "\n",
    "### Constants used to identify neighbor features in the input.\n",
    "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "NBR_WEIGHT_SUFFIX = '_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "  \"\"\"Hyperparameters used for training.\"\"\"\n",
    "  def __init__(self):\n",
    "    ### dataset parameters\n",
    "    self.num_classes = 7\n",
    "    self.max_seq_length = 1433\n",
    "    ### neural graph learning parameters\n",
    "    self.distance_type = nsl.configs.DistanceType.L2\n",
    "    self.graph_regularization_multiplier = 0.1\n",
    "    self.num_neighbors = 1\n",
    "    ### model architecture\n",
    "    self.num_fc_units = [50, 50]\n",
    "    ### training parameters\n",
    "    self.train_epochs = 100\n",
    "    self.batch_size = 128\n",
    "    self.dropout_rate = 0.5\n",
    "    ### eval parameters\n",
    "    self.eval_steps = None  # All instances in the test set are evaluated.\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_example(example_proto):\n",
    "  \"\"\"Extracts relevant fields from the `example_proto`.\n",
    "\n",
    "  Args:\n",
    "    example_proto: An instance of `tf.train.Example`.\n",
    "\n",
    "  Returns:\n",
    "    A pair whose first value is a dictionary containing relevant features\n",
    "    and whose second value contains the ground truth labels.\n",
    "  \"\"\"\n",
    "  # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
    "  # original raw text. A default value is required for examples that don't\n",
    "  # have the feature.\n",
    "  feature_spec = {\n",
    "      'words':\n",
    "          tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
    "                                tf.int64,\n",
    "                                default_value=tf.constant(\n",
    "                                    0,\n",
    "                                    dtype=tf.int64,\n",
    "                                    shape=[HPARAMS.max_seq_length])),\n",
    "      'label':\n",
    "          tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
    "  }\n",
    "  # We also extract corresponding neighbor features in a similar manner to\n",
    "  # the features above.\n",
    "  for i in range(HPARAMS.num_neighbors):\n",
    "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
    "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
    "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
    "        [HPARAMS.max_seq_length],\n",
    "        tf.int64,\n",
    "        default_value=tf.constant(\n",
    "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
    "\n",
    "    # We assign a default value of 0.0 for the neighbor weight so that\n",
    "    # graph regularization is done on samples based on their exact number\n",
    "    # of neighbors. In other words, non-existent neighbors are discounted.\n",
    "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
    "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
    "\n",
    "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "  labels = features.pop('label')\n",
    "  return features, labels\n",
    "\n",
    "\n",
    "def make_dataset(file_path, training=False):\n",
    "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
    "\n",
    "  Args:\n",
    "    file_path: Name of the file in the `.tfrecord` format containing\n",
    "      `tf.train.Example` objects.\n",
    "    training: Boolean indicating if we are in training mode.\n",
    "\n",
    "  Returns:\n",
    "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
    "    objects.\n",
    "  \"\"\"\n",
    "  dataset = tf.data.TFRecordDataset([file_path])\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(10000)\n",
    "  dataset = dataset.map(parse_example)\n",
    "  dataset = dataset.batch(HPARAMS.batch_size)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
    "test_dataset = make_dataset(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[5 4 3 1 1 2 5 2 6 2 6 4 1 1 6 2 4 2 5 3 2 6 1 0 3 0 6 2 2 0 3 1 2 1 3 5 2\n",
      " 1 2 2 0 1 4 4 1 3 1 1 4 2 2 5 2 6 4 3 3 0 2 2 4 3 3 0 2 6 2 1 6 4 5 2 1 6\n",
      " 6 1 2 0 4 0 3 4 5 1 3 1 6 2 2 2 2 3 2 0 2 1 5 4 0 5 5 6 2 6 2 2 1 6 4 3 2\n",
      " 1 2 6 2 1 2 6 2 1 4 1 1 3 6 3 2 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[5 2 2 2 1 2 6 3 2 3 6 1 3 6 4 4 2 3 3 0 2 0 5 2 1 0 6 3 6 4 2 2 3 0 4 2 2\n",
      " 2 2 3 2 2 2 0 2 2 2 2 4 2 3 4 0 2 6 2 1 4 2 0 0 1 4 2 6 0 5 2 2 3 2 5 2 5\n",
      " 2 3 2 2 2 2 2 6 6 3 2 4 2 6 3 2 2 6 2 4 2 2 1 3 4 6 0 0 2 4 2 1 3 6 6 2 6\n",
      " 6 6 1 4 6 4 3 6 6 0 0 2 6 2 4 0 0], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in test_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# In order to demonstrate the use of graph regularization, we build a base model for this problem first. We will use a simple feed-forward neural network with 2 hidden layers and dropout in between. We illustrate the creation of the base model using all model types supported by the tf.Keras framework -- sequential, functional, and subclass.\n",
    "\n",
    "# Sequential base model\n",
    "def make_mlp_sequential_model(hparams):\n",
    "  \"\"\"Creates a sequential multi-layer perceptron model.\"\"\"\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(\n",
    "      tf.keras.layers.InputLayer(\n",
    "          input_shape=(hparams.max_seq_length,), name='words'))\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  model.add(\n",
    "      tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32)))\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "    # For sequential models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    model.add(tf.keras.layers.Dropout(hparams.dropout_rate))\n",
    "  model.add(tf.keras.layers.Dense(hparams.num_classes, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp_functional_model(hparams):\n",
    "  \"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "  inputs = tf.keras.Input(\n",
    "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
    "\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  cur_layer = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.keras.backend.cast(x, tf.float32))(\n",
    "          inputs)\n",
    "\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "    # For functional models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(\n",
    "      hparams.num_classes, activation='softmax')(\n",
    "          cur_layer)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp_subclass_model(hparams):\n",
    "  \"\"\"Creates a multi-layer perceptron subclass model in Keras.\"\"\"\n",
    "\n",
    "  class MLP(tf.keras.Model):\n",
    "    \"\"\"Subclass model defining a multi-layer perceptron.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "      super(MLP, self).__init__()\n",
    "      # Input is already one-hot encoded in the integer format. We create a\n",
    "      # layer to cast it to floating point format here.\n",
    "      self.cast_to_float_layer = tf.keras.layers.Lambda(\n",
    "          lambda x: tf.keras.backend.cast(x, tf.float32))\n",
    "      self.dense_layers = [\n",
    "          tf.keras.layers.Dense(num_units, activation='relu')\n",
    "          for num_units in hparams.num_fc_units\n",
    "      ]\n",
    "      self.dropout_layer = tf.keras.layers.Dropout(hparams.dropout_rate)\n",
    "      self.output_layer = tf.keras.layers.Dense(\n",
    "          hparams.num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      cur_layer = self.cast_to_float_layer(inputs['words'])\n",
    "      for dense_layer in self.dense_layers:\n",
    "        cur_layer = dense_layer(cur_layer)\n",
    "        cur_layer = self.dropout_layer(cur_layer, training=training)\n",
    "\n",
    "      outputs = self.output_layer(cur_layer)\n",
    "\n",
    "      return outputs\n",
    "\n",
    "  return MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "words (InputLayer)           [(None, 1433)]            0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1433)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                71700     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a base MLP model using the functional API.\n",
    "# Alternatively, you can also create a sequential or subclass base model using\n",
    "# the make_mlp_sequential_model() or make_mlp_subclass_model() functions\n",
    "# respectively, defined above. Note that if a subclass model is used, its\n",
    "# summary cannot be generated until it is built.\n",
    "base_model_tag, base_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 1.8889 - accuracy: 0.2538\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.8066 - accuracy: 0.3063\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.7132 - accuracy: 0.3285\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.6182 - accuracy: 0.3773\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.4868 - accuracy: 0.4561\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.3525 - accuracy: 0.5271\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.2295 - accuracy: 0.5754\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.0909 - accuracy: 0.6432\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.9739 - accuracy: 0.6812\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.8603 - accuracy: 0.7323\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.8051 - accuracy: 0.7415\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.7299 - accuracy: 0.7680\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.7958\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6190 - accuracy: 0.8005\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5704 - accuracy: 0.8292\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5085 - accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4830 - accuracy: 0.8557\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4313 - accuracy: 0.8664\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3922 - accuracy: 0.8789\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3823 - accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3615 - accuracy: 0.8942\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3233 - accuracy: 0.9007\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3180 - accuracy: 0.9086\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3010 - accuracy: 0.9239\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2911 - accuracy: 0.9114\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2814 - accuracy: 0.9155\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2518 - accuracy: 0.9267\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2374 - accuracy: 0.9350\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9350\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2135 - accuracy: 0.9392\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2019 - accuracy: 0.9425\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2019 - accuracy: 0.9452\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1863 - accuracy: 0.9531\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9499\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1668 - accuracy: 0.9568\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1680 - accuracy: 0.9522\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.9610\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1614 - accuracy: 0.9503\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1472 - accuracy: 0.9610\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1455 - accuracy: 0.9564\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9619\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1219 - accuracy: 0.9698\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1317 - accuracy: 0.9619\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1230 - accuracy: 0.9633\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1270 - accuracy: 0.9652\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1117 - accuracy: 0.9666\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1160 - accuracy: 0.9703\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1084 - accuracy: 0.9759\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1032 - accuracy: 0.9722\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1066 - accuracy: 0.9684\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1128 - accuracy: 0.9698\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9708\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0945 - accuracy: 0.9759\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1110 - accuracy: 0.9712\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0981 - accuracy: 0.9759\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0908 - accuracy: 0.9735\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0844 - accuracy: 0.9777\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9740\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0934 - accuracy: 0.9726\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 0.9782\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9828\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0915 - accuracy: 0.9749\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0719 - accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0829 - accuracy: 0.9726\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0735 - accuracy: 0.9777\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9787\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0658 - accuracy: 0.9838\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0727 - accuracy: 0.9782\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0670 - accuracy: 0.9810\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0786 - accuracy: 0.9722\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9833\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0697 - accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9856\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0633 - accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.9838\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0654 - accuracy: 0.9814\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0654 - accuracy: 0.9810\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0577 - accuracy: 0.9865\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0562 - accuracy: 0.9861\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0501 - accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0628 - accuracy: 0.9852\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0605 - accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0544 - accuracy: 0.9852\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0532 - accuracy: 0.9865\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9819\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0493 - accuracy: 0.9856\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0494 - accuracy: 0.9870\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0477 - accuracy: 0.9847\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9847\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0458 - accuracy: 0.9865\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0496 - accuracy: 0.9856\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0501 - accuracy: 0.9852\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0506 - accuracy: 0.9852\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0495 - accuracy: 0.9865\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0475 - accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d90b878d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the base MLP model\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3270 - accuracy: 0.7902\n",
      "\n",
      "\n",
      "Eval accuracy for  Base MLP model :  0.7902351\n",
      "Eval loss for  Base MLP model :  1.3269529938697815\n"
     ]
    }
   ],
   "source": [
    "# Helper function to print evaluation metrics.\n",
    "def print_metrics(model_desc, eval_metrics):\n",
    "  \"\"\"Prints evaluation metrics.\n",
    "\n",
    "  Args:\n",
    "    model_desc: A description of the model.\n",
    "    eval_metrics: A dictionary mapping metric names to corresponding values. It\n",
    "      must contain the loss and accuracy metrics.\n",
    "  \"\"\"\n",
    "  print('\\n')\n",
    "  print('Eval accuracy for ', model_desc, ': ', eval_metrics['accuracy'])\n",
    "  print('Eval loss for ', model_desc, ': ', eval_metrics['loss'])\n",
    "  if 'graph_loss' in eval_metrics:\n",
    "    print('Eval graph loss for ', model_desc, ': ', eval_metrics['graph_loss'])\n",
    "\n",
    "eval_results = dict(\n",
    "    zip(base_model.metrics_names,\n",
    "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('Base MLP model', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashley\\pycharmprojects\\big5\\venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\users\\ashley\\pycharmprojects\\big5\\venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 81ms/step - loss: 1.9354 - accuracy: 0.1865 - graph_loss: 0.0074\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.8513 - accuracy: 0.2961 - graph_loss: 0.0100\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.7601 - accuracy: 0.3364 - graph_loss: 0.0208\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.6516 - accuracy: 0.3694 - graph_loss: 0.0431\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.5290 - accuracy: 0.4255 - graph_loss: 0.0696\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.3851 - accuracy: 0.4919 - graph_loss: 0.1058\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.2622 - accuracy: 0.5619 - graph_loss: 0.1360\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1384 - accuracy: 0.6153 - graph_loss: 0.1695\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.0113 - accuracy: 0.6914 - graph_loss: 0.1965\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.9290 - accuracy: 0.7049 - graph_loss: 0.2261\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.8313 - accuracy: 0.7480 - graph_loss: 0.2451\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.7247 - accuracy: 0.7912 - graph_loss: 0.2702\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.8032 - graph_loss: 0.2759\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6174 - accuracy: 0.8246 - graph_loss: 0.2984\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5792 - accuracy: 0.8418 - graph_loss: 0.2962\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.8561 - graph_loss: 0.3242\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4863 - accuracy: 0.8654 - graph_loss: 0.3138\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4661 - accuracy: 0.8756 - graph_loss: 0.3283\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4308 - accuracy: 0.8756 - graph_loss: 0.3220\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4046 - accuracy: 0.8970 - graph_loss: 0.3112\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.8933 - graph_loss: 0.3295\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3715 - accuracy: 0.9049 - graph_loss: 0.3336\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.9123 - graph_loss: 0.3201\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3267 - accuracy: 0.9230 - graph_loss: 0.3385\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.9267 - graph_loss: 0.3428\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2837 - accuracy: 0.9323 - graph_loss: 0.3334\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2909 - accuracy: 0.9197 - graph_loss: 0.3447\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2637 - accuracy: 0.9360 - graph_loss: 0.3308\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2482 - accuracy: 0.9360 - graph_loss: 0.3384\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2377 - accuracy: 0.9452 - graph_loss: 0.3319\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2334 - accuracy: 0.9420 - graph_loss: 0.3382\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2042 - accuracy: 0.9527 - graph_loss: 0.3211\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.9499 - graph_loss: 0.3466\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2147 - accuracy: 0.9531 - graph_loss: 0.3391\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1965 - accuracy: 0.9555 - graph_loss: 0.3397\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9675 - graph_loss: 0.3410\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1779 - accuracy: 0.9601 - graph_loss: 0.3368\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9652 - graph_loss: 0.3460\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1835 - accuracy: 0.9610 - graph_loss: 0.3437\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1819 - accuracy: 0.9564 - graph_loss: 0.3500\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.9689 - graph_loss: 0.3360\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1585 - accuracy: 0.9633 - graph_loss: 0.3386\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1642 - accuracy: 0.9633 - graph_loss: 0.3452\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1551 - accuracy: 0.9689 - graph_loss: 0.3472\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1494 - accuracy: 0.9703 - graph_loss: 0.3398\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1418 - accuracy: 0.9740 - graph_loss: 0.3344\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 0.9703 - graph_loss: 0.3529\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1343 - accuracy: 0.9759 - graph_loss: 0.3454\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1276 - accuracy: 0.9763 - graph_loss: 0.3513\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.9726 - graph_loss: 0.3417\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1310 - accuracy: 0.9740 - graph_loss: 0.3415\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9726 - graph_loss: 0.3334\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1300 - accuracy: 0.9749 - graph_loss: 0.3478\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1340 - accuracy: 0.9726 - graph_loss: 0.3494\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1252 - accuracy: 0.9740 - graph_loss: 0.3377\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1252 - accuracy: 0.9773 - graph_loss: 0.3459\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1163 - accuracy: 0.9805 - graph_loss: 0.3404\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1122 - accuracy: 0.9777 - graph_loss: 0.3424\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1156 - accuracy: 0.9805 - graph_loss: 0.3452\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1256 - accuracy: 0.9731 - graph_loss: 0.3490\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1116 - accuracy: 0.9842 - graph_loss: 0.3485\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1045 - accuracy: 0.9824 - graph_loss: 0.3434\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1053 - accuracy: 0.9810 - graph_loss: 0.3460\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1068 - accuracy: 0.9814 - graph_loss: 0.3424\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1058 - accuracy: 0.9810 - graph_loss: 0.3491\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1140 - accuracy: 0.9810 - graph_loss: 0.3463\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1058 - accuracy: 0.9805 - graph_loss: 0.3409\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0979 - accuracy: 0.9819 - graph_loss: 0.3383\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0971 - accuracy: 0.9819 - graph_loss: 0.3457\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0993 - accuracy: 0.9824 - graph_loss: 0.3412\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0973 - accuracy: 0.9828 - graph_loss: 0.3452\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0964 - accuracy: 0.9865 - graph_loss: 0.3439\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9805 - graph_loss: 0.3519\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0876 - accuracy: 0.9852 - graph_loss: 0.3365\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0879 - accuracy: 0.9898 - graph_loss: 0.3378\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0992 - accuracy: 0.9814 - graph_loss: 0.3503\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9884 - graph_loss: 0.3403\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0913 - accuracy: 0.9842 - graph_loss: 0.3420\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9814 - graph_loss: 0.3449\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9824 - graph_loss: 0.3430\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0859 - accuracy: 0.9879 - graph_loss: 0.3426\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0943 - accuracy: 0.9833 - graph_loss: 0.3413\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0850 - accuracy: 0.9870 - graph_loss: 0.3406\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9903 - graph_loss: 0.3394\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0914 - accuracy: 0.9833 - graph_loss: 0.3371\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0852 - accuracy: 0.9861 - graph_loss: 0.3441\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9852 - graph_loss: 0.3358\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0872 - accuracy: 0.9861 - graph_loss: 0.3438\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0902 - accuracy: 0.9856 - graph_loss: 0.3449\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0802 - accuracy: 0.9865 - graph_loss: 0.3439\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0858 - accuracy: 0.9810 - graph_loss: 0.3339\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0783 - accuracy: 0.9879 - graph_loss: 0.3368\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0795 - accuracy: 0.9893 - graph_loss: 0.3329\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0804 - accuracy: 0.9884 - graph_loss: 0.3343\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0814 - accuracy: 0.9861 - graph_loss: 0.3336\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9907 - graph_loss: 0.3319\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0804 - accuracy: 0.9852 - graph_loss: 0.3392\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 0.9875 - graph_loss: 0.3452\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0782 - accuracy: 0.9875 - graph_loss: 0.3338\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9912 - graph_loss: 0.3371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d928cc748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a new base MLP model.\n",
    "base_reg_model_tag, base_reg_model = 'FUNCTIONAL', make_mlp_functional_model(\n",
    "    HPARAMS)\n",
    "\n",
    "# Wrap the base MLP model with graph regularization.\n",
    "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=HPARAMS.num_neighbors,\n",
    "    multiplier=HPARAMS.graph_regularization_multiplier,\n",
    "    distance_type=HPARAMS.distance_type,\n",
    "    sum_over_axis=-1)\n",
    "graph_reg_model = nsl.keras.GraphRegularization(base_reg_model,\n",
    "                                                graph_reg_config)\n",
    "graph_reg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "graph_reg_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0302 - accuracy: 0.8174 - graph_loss: 0.0000e+00\n",
      "\n",
      "\n",
      "Eval accuracy for  MLP + graph regularization :  0.81735986\n",
      "Eval loss for  MLP + graph regularization :  1.0301653563976287\n",
      "Eval graph loss for  MLP + graph regularization :  0.0\n"
     ]
    }
   ],
   "source": [
    "eval_results = dict(\n",
    "    zip(graph_reg_model.metrics_names,\n",
    "        graph_reg_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('MLP + graph regularization', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GraphRegularization\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 7)                 74607     \n",
      "_________________________________________________________________\n",
      "neighbor_features (NeighborF multiple                  0         \n",
      "_________________________________________________________________\n",
      "graph_loss (PairwiseDistance multiple                  0         \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
